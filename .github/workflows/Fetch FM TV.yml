# This is an improved workflow for fetching and wrapping M3U files
name: Fetch TV-FM Files

on:
  schedule:
    - cron: '30 * * * *'
  workflow_dispatch: {} # Enables manual triggering

permissions:
  contents: write

jobs:
  download_and_commit:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download unwrapped M3U Plus file
        run: wget "${{ secrets.IPTV_M3U_URL }}" -O "unwrapped.m3u"

      - name: Download EPG XML file
        run: wget "${{ secrets.IPTV_EPG_URL }}" -O "channel playlist.xml"

      - name: Transform URLs to wrapped format
        env:
          # Pass the full M3U URL into the script's environment
          IPTV_M3U_URL: ${{ secrets.IPTV_M3U_URL }}
        run: |
          python3 << 'EOF'
          import base64
          import re
          import json
          import urllib.parse
          import os
          import traceback

          def wrap_m3u_urls(input_file, output_file):
              """
              Reads an unwrapped M3U file and transforms stream URLs into the proxy-wrapped format.
              Enhanced with better parsing and error handling.
              URLs ending with /#.mkv are passed through unchanged.
              """
              # Get the full M3U URL from environment variables
              m3u_url = os.environ.get('IPTV_M3U_URL')
              if not m3u_url:
                  print("Error: IPTV_M3U_URL not found in environment variables.")
                  return False

              # Parse the URL to extract username and password
              try:
                  parsed_url = urllib.parse.urlparse(m3u_url)
                  query_params = urllib.parse.parse_qs(parsed_url.query)
                  username = query_params['username'][0]
                  password = query_params['password'][0]
              except (KeyError, IndexError) as e:
                  print(f"Error: Could not parse 'username' and 'password' from IPTV_M3U_URL: {e}")
                  return False
              
              # Construct the prefix dynamically using extracted credentials
              PREFIX = f"http://alt.xtream-ie.org/{username}/{password}/1"
              SUFFIX = "/fast"

              # Regex to find values from the #EXTINF line
              CUID_PATTERN = re.compile(r'CUID=\"(\d+)\"')
              
              print(f"Starting M3U transformation: {input_file} -> {output_file}")

              try:
                  with open(input_file, 'r', encoding='utf-8', errors='ignore') as infile, \
                       open(output_file, 'w', encoding='utf-8') as outfile:
                      
                      lines = infile.readlines()
                      
                      # Check for M3U header and validate
                      if not lines or not lines[0].strip().startswith("#EXTM3U"):
                          print("Error: Input file is missing valid '#EXTM3U' header.")
                          return False

                      # Write header with the EPG URL
                      outfile.write('#EXTM3U url-tvg="https://tinyurl.com/FMTV-L1VE-EPG-XML"\n')
                      
                      i = 1 # Start processing from the second line
                      processed_count = 0
                      skipped_count = 0
                      error_count = 0
                      
                      while i < len(lines):
                          extinf_line = lines[i].strip()
                          
                          if extinf_line.startswith("#EXTINF"):
                              outfile.write(extinf_line + '\n')
                              
                              # Safety check for next line
                              if i + 1 >= len(lines):
                                  print(f"Warning: EXTINF at line {i} has no URL following")
                                  i += 1
                                  continue

                              url_line = lines[i+1].strip()
                              
                              # Handle empty URL lines
                              if not url_line:
                                  outfile.write('\n')
                                  i += 2
                                  continue
                              
                              # Check if URL ends with /#.mkv - if so, skip encoding and pass through
                              if url_line.endswith('/#.mkv'):
                                  print(f"Info: Skipping encoding for .mkv URL at line {i+1}")
                                  outfile.write(url_line + '\n')
                                  skipped_count += 1
                                  i += 2
                                  continue
                              
                              # Check if URL is already wrapped (contains base64-like patterns or specific markers)
                              if url_line.startswith('/_v1_akmzed/') or not url_line.startswith('http'):
                                  # This appears to be an already-wrapped or malformed URL fragment
                                  # Try to reconstruct it with the PREFIX if it looks like encoded payload
                                  if url_line.startswith('/_v1_akmzed/') or url_line.startswith('/'):
                                      # This is likely a partial wrapped URL, reconstruct it
                                      reconstructed_url = f"{PREFIX}{url_line.lstrip('/')}"
                                      print(f"Info: Reconstructed partial URL at line {i+1}")
                                      outfile.write(reconstructed_url + '\n')
                                      processed_count += 1
                                  else:
                                      print(f"Warning: Invalid URL at line {i+1}: {url_line[:50]}")
                                      outfile.write(url_line + '\n')
                                      error_count += 1
                                  i += 2
                                  continue
                              
                              # Extract CUID
                              cuid_match = CUID_PATTERN.search(extinf_line)
                              
                              if not cuid_match:
                                  print(f"Warning: No CUID found at line {i}, passing through unchanged")
                                  outfile.write(url_line + '\n')
                                  error_count += 1
                                  i += 2
                                  continue

                              cuid = int(cuid_match.group(1))
                              
                              # Build the JSON payload
                              try:
                                  payload_data = {"url": url_line, "id": cuid}
                                  payload_str = json.dumps(payload_data, ensure_ascii=False)
                                  
                                  # Base64 Encode the payload
                                  encoded_payload = base64.b64encode(payload_str.encode('utf-8')).decode('utf-8')
                                  
                                  # URL-safe encode the result
                                  url_safe_payload = encoded_payload.replace('=', '%3D')
                                  
                                  # Construct the final wrapped URL
                                  wrapped_url = f'{PREFIX}{url_safe_payload}{SUFFIX}'
                                  
                                  outfile.write(wrapped_url + '\n')
                                  processed_count += 1
                                  
                              except Exception as e:
                                  print(f"Error encoding URL at line {i+1}: {e}")
                                  outfile.write(url_line + '\n')
                                  error_count += 1
                              
                              i += 2
                          else:
                              # Pass through non-EXTINF lines (comments, etc.)
                              outfile.write(lines[i]) 
                              i += 1
                      
                      print(f"Transformation complete: {processed_count} URLs encoded, {skipped_count} .mkv URLs skipped, {error_count} errors")
                      return error_count == 0

              except FileNotFoundError:
                  print(f"Error: File {input_file} was not found.")
                  return False
              except Exception as e:
                  print(f"An unexpected error occurred: {e}")
                  traceback.print_exc()
                  return False

          # Execute the transformation
          success = wrap_m3u_urls('unwrapped.m3u', 'channel playlist.m3u')
          exit(0 if success else 1)
          EOF

      - name: Add files to Git
        run: |
          git add "channel playlist.m3u"
          git add "channel playlist.xml"

      - name: Check for changes before commit
        id: changes
        run: |
          if git diff --cached --quiet; then
            echo "no changes"
            echo "changes_detected=false" >> $GITHUB_ENV
          else
            echo "changes_detected=true" >> $GITHUB_ENV
          fi

      - name: Commit changes if any
        if: env.changes_detected == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "github-actions[bot]"
          git commit -m "Updated channel playlist files (M3U with wrapped URLs and EPG XML)"

      - name: Force push changes if commit happened
        if: env.changes_detected == 'true'
        run: |
          git push origin main --force
